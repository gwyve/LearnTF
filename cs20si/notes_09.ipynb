{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 第九课\n",
    "第八课找了google brain的人[Jusin Johnson](https://research.google.com/pubs/JonathonShlens.html)过来讲东西，网上并找不到第八课具体资料。只能在第九课开头的时候看到，讲师在说“ Because of the guest lectures, we haven’t been able to get to some important concepts that\n",
    "a lot of people seem to be confused about.”\n",
    "\n",
    "\n",
    "#### Queues and Coordinators\n",
    "这个就是说了一个多线程的事儿，他说的那么多，就是说了一句话：“多线程很重要，想知道咋用，你去看代码”\n",
    "\n",
    "tf.Coordinator是用来多个线程一起停止并报告异常                                                \n",
    "tf.train.QueueRunner是生成运行tensor的线程的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 我又一次开始敲代码分析代码\n",
    "# https://github.com/chiphuyen/tf-stanford-tutorials/blob/master/examples/09_queue_example.py\n",
    "# 这一块我分析得也是云里雾里，待之后再回头看\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "N_SAMPLES = 1000\n",
    "NUM_THREADS = 4\n",
    "\n",
    "data = 10 * np.random.randn(N_SAMPLES,4) + 1\n",
    "# 生成一个[1000.4]的这么一个矩阵\n",
    "# np.random.randn(d0,d1,,,,,dn) 参数为维数\n",
    "\n",
    "target = np.random.randint(0,2,size=N_SAMPLES)\n",
    "# 生成一个只有01的[1000]的矩阵\n",
    "# numpy.random.randint(low, high=None, size=None, dtype='l')，low是生成中最小的数，high是上界\n",
    "\n",
    "\n",
    "queue = tf.FIFOQueue(capacity=50,dtypes=[tf.float32,tf.int32],shapes=[[4],[]])\n",
    "# 建立一个容量是50的队列\n",
    "\n",
    "enqueue_op = queue.enqueue_many([data,target])  # 取出队列中的数据；我的理解，这里是把队列这个东西跟data做一个链接，把data放到queue里面\n",
    "\n",
    "data_sample,label_sample = queue.dequeue() # 这个是创建了一个从queue里面取数据的工具\n",
    "\n",
    "\n",
    "qr = tf.train.QueueRunner(queue,[enqueue_op] * NUM_THREADS) \n",
    "# 定义一个queueRunner，这个负责对线程进行操作\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    coord = tf.train.Coordinator()\n",
    "    enqueue_threads = qr.create_threads(sess,coord = coord, start = True)\n",
    "    # 获得thread\n",
    "    \n",
    "    for step in xrange(100):\n",
    "        if coord.should_stop():\n",
    "            # 如果所有的线程都停了，那么也应该停下来\n",
    "            break\n",
    "        data_batch,label_batch = sess.run([data_sample,label_sample])\n",
    "        coord.request_stop()\n",
    "        # 停下线程， 调用了request_stop()之后，调用should_stop()返回 True\n",
    "        coord.join(enqueue_threads)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Readers\n",
    "这里说了读取数据有三种形式：\n",
    "- 通过常量读取\n",
    "- 通过feed dict 读取\n",
    "- TextLineReader\n",
    "\n",
    "前两种，只能保证数据从storage读出，不能从device读出\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.ops.io_ops.ReaderBase"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TFRedcord的类型：\n",
    "tf.TextLineReader # 按行返回\n",
    "# Outputs the lines of a file delimited by newlines\n",
    "# E.g. text files, CSV files\n",
    "\n",
    "tf.FixedLengthRecordReader  # 按固定长度返回\n",
    "# Outputs the entire file when all files have same fixed lengths\n",
    "# E.g. each MNIST file has 28 x 28 pixels, CIFAR-10 32 x 32 x 3\n",
    "\n",
    "tf.WholeFileReader   # 返回去全部文件内容\n",
    "# Outputs the entire file content. This is useful when each file contains a sample\n",
    "\n",
    "tf.TFRecordReader   # 返回二进制数据\n",
    "# Reads samples from TensorFlow's own binary format (TFRecord)\n",
    "\n",
    "tf.ReaderBase   # 可以根据他重新写reader\n",
    "# Allows you to create your own readers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 使用reader要先创建一个queue用来存这些文件的名字\n",
    "\n",
    "filename_queue = tf.train.string_input_producer([\"heart.csv\"])\n",
    "reader = tf.TextLineReader(skip_header_lines=1)  # skip_header_lines 是每个文件跳过开头的多少行\n",
    "# it means you choose to skip the first line for every file in the queue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 这里使用之前用到的 FIFOQueue\n",
    "\n",
    "filenames = [\"heart.csv\"]\n",
    "filename_queue = tf.train.string_input_producer(filenames)\n",
    "reader = tf.TextLineReader(skip_header_lines=1) # skip the first line in the file\n",
    "key, value = reader.read(filename_queue) # key是file的唯一标识scalar string 值 value是 string tensor\n",
    "with tf.Session() as sess:\n",
    "     coord = tf.train.Coordinator()\n",
    "     threads = tf.train.start_queue_runners(coord=coord)\n",
    "     print sess.run(key) # data/heart.csv:2\n",
    "     print sess.run(value) # 144,0.01,4.41,28.61,Absent,55,28.87,2.06,63,1\n",
    "     coord.request_stop()\n",
    "     coord.join(threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 把读出的数据，转换成可以feed用的数据\n",
    "\n",
    "# record_defaults 存在的意义：\n",
    "# 1、告诉decoder说需要的数据类型\n",
    "# 2、产生默认值\n",
    "\n",
    "record_defaults = [[1.0] for _ in range(N_FEATURES)] # define all features to be floats\n",
    "# 定义一个默认的record类型 \n",
    "record_defaults[4] = [''] # make the fifth feature string\n",
    "record_defaults.append([1])\n",
    "content = tf.decode_csv(value, record_defaults=record_defaults)\n",
    "\n",
    "# have our content is a list of 10 elements, 8 are floats, 1 is string, and 1 is integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 装换 类型\n",
    "# convert the 5th column (present/absent) to the binary value 0 and 1\n",
    "condition = tf.equal(content[4], tf.constant('Present'))\n",
    "content[4] = tf.select(condition, tf.constant(1.0), tf.constant(0.0))\n",
    "# pack all 9 features into a tensor\n",
    "features = tf.pack(content[:N_FEATURES])\n",
    "# assign the last column to label\n",
    "label = content[-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 设置返回的batch多少\n",
    "# minimum number elements in the queue after a dequeue, used to ensure that the samples are sufficiently mixed\n",
    "# I think 10 times the BATCH_SIZE is sufficient\n",
    "min_after_dequeue = 10 * BATCH_SIZE\n",
    "# the maximum number of elements in the queue\n",
    "capacity = 20 * BATCH_SIZE\n",
    "# shuffle the data to generate BATCH_SIZE sample pairs\n",
    "data_batch, label_batch = tf.train.shuffle_batch([features, label], batch_size=BATCH_SIZE,\n",
    " capacity=capacity, min_after_dequeue=min_after_dequeue)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TFRecord\n",
    "他说二进制的文件，快，然而，我并不知道是为什么"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 以下是把图片转换成byte string\n",
    "\n",
    "def get_image_binary(filename):\n",
    "     image = Image.open(filename)\n",
    "     image = np.asarray(image, np.uint8)\n",
    "     shape = np.array(image.shape, np.int32)\n",
    "     return shape.tobytes(), image.tobytes() # convert image to raw data bytes in the array.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 把byte string 转成 TFRecord 文件\n",
    "\n",
    "def write_to_tfrecord(label, shape, binary_image, tfrecord_file):\n",
    "     \"\"\" This example is to write a sample to TFRecord file. If you want to write\n",
    "     more samples, just use a loop.\n",
    "     \"\"\"\n",
    "     writer = tf.python_io.TFRecordWriter(tfrecord_file)\n",
    "     # write label, shape, and image content to the TFRecord file\n",
    "     example = tf.train.Example(features=tf.train.Features(feature={\n",
    "             'label': tf.train.Feature(bytes_list=tf.train.BytesList(value=[label])),\n",
    "             'shape': tf.train.Feature(bytes_list=tf.train.BytesList(value=[shape])),\n",
    "             'image':tf.train.Feature(bytes_list=tf.train.BytesList(\n",
    "             value=[binary_image]))\n",
    "         }))\n",
    "     writer.write(example.SerializeToString())\n",
    "     writer.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 读取TFRecord文件\n",
    "\n",
    "def read_from_tfrecord(filenames):\n",
    "     tfrecord_file_queue = tf.train.string_input_producer(filenames, name='queue')\n",
    "     reader = tf.TFRecordReader()\n",
    "     _, tfrecord_serialized = reader.read(tfrecord_file_queue)\n",
    "     # label and image are stored as bytes but could be stored as\n",
    "     # int64 or float64 values in a serialized tf.Example protobuf.\n",
    "     tfrecord_features = tf.parse_single_example(tfrecord_serialized,\n",
    "                         features={\n",
    "                             'label': tf.FixedLenFeature([], tf.string),\n",
    "                             'shape': tf.FixedLenFeature([], tf.string),\n",
    "                             'image': tf.FixedLenFeature([], tf.string),\n",
    "                         }, name='features')\n",
    "     # image was saved as uint8, so we have to decode as uint8.\n",
    "     image = tf. decode_raw(tfrecord_features['image'], tf.uint8)\n",
    "     shape = tf.decode_raw(tfrecord_features['shape'], tf.int32)\n",
    "     # the image tensor is flattened out, so we have to reconstruct the shape\n",
    "     image = tf.reshape(image, shape)\n",
    "     label = tf.cast(tfrecord_features['label'], tf.string)\n",
    "     return label, shape, image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
